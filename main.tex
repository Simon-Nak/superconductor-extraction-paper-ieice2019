\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{authblk}
\usepackage{tabularx}
\usepackage{url}
\usepackage{verbatimbox}

\title{Proposal of Automatic Extraction Framework of Superconductors related Information from Scientific literature}

\author[1]{Luca Foppiano\thanks{FOPPIANO.Luca@nims.go.jp}}
\author[1]{Thaer M. Dieb\thanks{MOUSTAFADIEB.Thaer@nims.go.jp}}
\author[1]{Akira Suzuki\thanks{SUZUKI.Akira3@nims.go.jp}}
\author[1]{Masashi Ishii\thanks{ISHII.Masashi@nims.go.jp}}
\affil[1]{Research and Services Division of Materials Data and Integrated System (MaDIS), National Institute for Materials Science (NIMS), 1-2-1 Sengen, Tsukuba, Ibaraki 305-0047, Japan}

% \date{April 2019}

\begin{document}

\maketitle

\begin{abstract}
Automatic collection of materials information from research papers using natural language processing is highly required for rapid materials development using big data, namely materials informatics (MI). Difficulty of this automatic collection is mainly caused by the variety of expressions in the papers, a device with tolerance to such variety is required to be developed. 
In this paper, we report an ongoing interdisciplinary work to construct the device for automatic collection of superconductor-related information from scientific literature using text mining techniques. We focused on identification of superconducting materials and their key property of critical temperature (Tc), and discussed machine learning (ML) techniques, including annotation strategies to obtain appropriate training data. We introduce a guideline for the annotation together with our several trails of ML on subsequent automatic data collection.
\end{abstract}

%% The table of content is there just for organisation purposes, will be removed 
\pagebreak

% \tableofcontents

% \pagebreak

%Research in superconductors is always articulated over two main axes, finding new conditions or discovering new materials (or combination of it) show new or better superconductivity properties. 
%In order to do so, material scientists needs to have rapid access to materials known to be superconductors and their properties without have to examine the thousand of papers related to it. Such data can also be used by further systems to compute generative models 


\section{Introduction}
% What is the problem we are trying to solve? What are the motivation behind this project? 

Automatic extraction of information from research papers using Natural Language processing is a highly required approach in many domains. In material research, the availability of large quantity of experimental data can give hints and ideas leading to new break-trough materials discoveries. Large availability of scientific papers and the expertise costs for manually generated such data justify the needs of Text and Data Mining automatic approaches.

Writing style, variability in experiment and result description are just two of the variables making this task particularly complex. Reason why the best approach to successfully deliver a functioning system is to reduce the complexity to the smallest viable product.

%% How research is made and what are the point of improvements?
\textit{Superconductivity is a phenomenon of exactly zero electrical resistance and expulsion of magnetic flux fields occurring in certain materials, called superconductors, when cooled below a characteristic critical temperature.}\footnote{\url{https://en.wikipedia.org/wiki/Superconductivity}}

The research in superconductor materials is articulated toward many different objectives. Discovery of new characteristic of well known materials, under new environment condition, like applied pressure or magnetic field. Combination of known superconductors with non-superconductors may lead to new materials with better characteristics, usually a higher critical temperature. 

% Add that introduction about the available databases, in particular NIMS, which has the problem that is not updated due to high costs of manual work
Currently there are several general material databases available, however when looking  at the superconductor sub-domain the main one is SuperCon\cite{SuperCon}. Hosted and maintained by the National Institute for Materials Science (NIMS) containing about 32k inorganic and about 558 organic superconductor material definitions. Since it was manually created, the high costs of the maintenance leads to and given high costs is not anymore up to date. 

% Why do we need such information? Why these information are important?
The availability of material information with detailed and precise granularity is a must-have for superconductors scientists. This data summarises decades of research and discoveries and can be potentially exploited in many areas. Machine learning or neural models can train generative models specialised in automatically predict critical temperature \cite{DBLP:journals/corr/abs-1812-01995} on new (pure or intercalated) materials. Large scale repositories with enhanced search specialised in semantic superconductor disambiguation, document recommendation, and so on. 

In this paper we describe the ongoing attempt to design a system aiming to automatically extract superconductor-related information from scientific literature based using Natural Language Processing techniques. In particular, we focus on extracting materials names linking it with they corresponding critical temperature (Tc) values.

Related works have been attempted in different domains, in particular  \cite{court2018auto} or [need to add more references]. Attempts in the superconductor sub-domains are not in our knowledge.  
% Related work \cite{nadev}, nature 
%We discuss the tag-set design and the establishment of the guidelines. 

We describe the development of a working prototype specialised in superconductors data extraction. We also develop an annotated corpus for material names recognition. Our system is based on an Open Source library for text mining from scholarly documents: Grobid \cite{GROBID} \cite{lopez2009grobid}. We evaluate the performance of the system using precision, recall and f-score. Such preliminary results are considered as our baseline for comparing further improvement of the system. 

% The paper describes the component of the system in Section \ref{sec:architecture} and the process to create the ML models. Preliminary results are enlisted in Section \ref{sec:results} 

\section{System architecture}
\label{sec:architecture}
In the domain of superconductor research T\textsubscript{c} plays a critical role because is the goal property and reference in superconducting research. For this reason, in the scope of this paper, we focus on extracting material names with their corresponding critical temperature. 

In collaboration with superconductor domain experts, we discussed the relevant information and how they were used in research activities. Depending on the writing style, these information are often presented as tables and plots because they summarise more effectively giving quicker understanding to a human reader. 
For simplicity we focus on extracting information from text, with the idea that complementary information can be added on a second stage. 

The system is divided into two components: first we extract relevant entities and secondly we link the Tc to their corresponding materials. 

% add schema / figure

In the extraction step, we build our implementation based on an Open Sources library called GROBID\cite{GROBID}. GROBID is a sequence labelling and document segmentation originally based on Machine Learning algorithm Conditional Random Field (CRF). It provides fully support for extraction of data from PDF and a build-in workflow for pre-annotating training data, evaluation and training. 

The PDF support in GROBID was an important feature because allowed us to work with a "standardised" format instead of dealing with several flavour of XML formats, as well as having data with noise 

Once relevant entities are extracted we process them in a second step using a Rule Based approach to classify any mention of temperature as critical temperature or not, and to link any critical temperature to the corresponding material. 

Our prototype contains a minimal model for superconductor material recognition, trained with 5 full documents (42 annotations in total) manually annotated by one person. We used only basic features with PDF font information and ChemSpot \cite{10.1093/bioinformatics/bts183} annotations indicating whether a token was a chemical FORMULA, SYSTEMATIC, COMPOUND. 

In order to keep the system light and easily manage dependencies, ChemSpot was integrated via a REST API interface. Since this functionality wasn't available we developed it as a wrapper \cite{chemspot-web}.    
The extraction of temperature was reused from another already implemented GROBID sub-module, called grobid-quantities\cite{grobid-quantities} specialised in general measurement extraction and normalisation covering a much larger scope. 

\section{Experiments and results}
\label{sec:experiments-results}

Preliminary evaluation for the superconductor model using a corpus of 42 entities among 5 papers, with a single tag \textless supercon\textgreater. We used 4 of these papers for training and 1 for evaluation. 

In GROBID evaluation framework evaluation measures (accuracy, precision and recall) are calculated at three different levels: tokens-level, field-level and instance-level. 
Evaluation at token-level is computed considering each token independently, field-level consider each continuous sequence of the same label (so a field, a sequence of several tokens which all belongs to the same labelled chunk, e.g. a title), finally instance-level is the score for the whole input, for instance a paragraph.

The output from GROBID is shown in the following listing: 

\begin{verbnobox}[\small]
===== Token-level results =====

label                accuracy     precision    recall       f1     

<supercon>           98.61        84.42        85.28        84.85  

all fields           98.61        84.42        85.28        84.85   (micro average)
                     98.61        84.42        85.28        84.85   (macro average)

===== Field-level results =====

label                accuracy     precision    recall       f1     

<supercon>           72.94        66.67        56.25        61.02  

all fields           72.94        66.67        56.25        61.02   (micro average)
                     72.94        66.67        56.25        61.02   (macro average)

===== Instance-level results =====

Total expected instances:   22
Correct instances:          15
Instance-level recall:      68.18
\end{verbnobox}

Field-level shows a f1-score of about 60\%. One of the reason why there is a difference of more than 20\% in f1-score between token-level and field-level can be attributed to the lack of training data, leading to mistakes in the edges of the fields.
We also noticed that 70\% of the paragraphs were correct, this result could look strange however we believe that is due to the lack of variability of examples creating a separation between examples correctly recognised (100\% in field and instances) and example incorrectly recognised (getting many wrong fields) (to be rewritten!)

% On a more larger scale, we experiment the extraction from a corpus of 500 PDF superconductors papers from three publishers: AIP, APS and IOP. The system extracted 5400 materials, however only 76 were linked to a critical temperature. We manually verified all of them and found out that 50 were correctly linked. 
On a more larger scale, we experiment the extraction from a corpus of 500 PDF superconductors papers from three publishers: AIP, APS and IOP as summarised in Table \ref{table:result-extraction} where the linked materials were evaluated manually. 

\begin{table}[h!]
    \centering
    \begin{tabular}{ | m{6em} | m{6em} | m{6em} | m{6em} | } 
    \hline
        \# of papers & Extracted materials & Linked material & Correctly linked materials  \\
    \hline
        500 & 5400 & 76 & 50 \\ 
    \hline
    \end{tabular}
    \label{table:result-extraction}
    \caption{Result of extraction on a corpus of 500 papers.}    
\end{table}

[TODO add examples of mistakes for the linking]

\section{Conclusion}
In this paper, we introduced a proposal for automatic extraction of superconductor related information from related publications using Sequence labelling. We report recall is that CRF can perform pretty well even without any special orthogonal information. We assessed that using a chemical entity recogniser contributed only for 1\% in term of f-score. On the other hand, ChemSpot increased the response time of a PDF document by approximately 10 times, making the system not particularly suitable for processing large collection of data. 

We are working in collaboration with the domain experts to produce a high quality corpus for superconductors which will be discussed in a further paper. 
We also plan to test the system using Bi-LSTM+CRF approach based on deep learning and embeddings once the corpus size reach critical mass to provide a reliable comparison. 

The linking using Rule Based approach has shown relatively low tolerance to noise, for two main reasons: firstly the data extracted from PDF is generally noisy with many characters wrongly extracted. Secondly the rules were too simple and weren't able to deal with complex cases, where the material name or the critical temperature was not explicitly recognised. 
We plan to experiment the following solutions: 1) improve the current approach adding more rules 2) implement a simple CRF model that allows the linking of relatively closed entities, and 3) study the possibility to exploit a sentence dependency parsing, bearing in mind the impact in performances should also be considered.

% Future works
% 
% \listoffigures
\pagebreak

\bibliography{references}
\bibliographystyle{plain}

\end{document}
